<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="author" content="Doug Hanson">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>User Testing | Doug Hanson | Web Development and Design, Perth</title>
  <meta name="description" content="What is User Testing? A look at what user testing is, why we need it, and a case study on how to start using it. A blog article by Doug Hanson.">
  <meta name="keywords" content="user testing, user experience, web design, designer, web development, front end developer, ux design, perth, doug hanson">

  <!-- build:css -->
  <link rel="stylesheet" href="css/styles.css" media="all">
  <!-- endbuild -->

</head>


<body class="blog-page">

  <!-- include frames and nav -->
  <?php include('inc/_nav.php'); ?>

  <div class="wrapper__outer">
    <div class="wrapper__inner">

      <div id="container">

        <article class="container">

          <!-- header image -->
          <!-- <header class="header"> -->
            <div class="bg-img" style="overflow: hidden; height: 360px; position: relative;">
              <img 
                src="img/user-testing-doug-hanson.jpg" 
                data-src="img/user-testing-doug-hanson.jpg" 
                class="lazy-load" alt="Interactive Jobs Portal" 
                style="bottom: -20px; margin: auto; width: 100%; min-width: 700px; "/>
            </div>
          <!-- </header> -->


            <!-- ###############################
            //   Page specific content
            #################################### -->
            <div class="col-lg-12">

              <h1 class="font-bold grey-6 margin-top-30">User Testing</h1>

              <p class="h3 subheading padding-0 margin-0">What is User Testing?</p>
              <p>User testing is the best way to understand how real users experience our website. The tests take place with real users to measure how ‘usable’ or ‘intuitive’ a website is and how easy it is for users to reach their goals. Unlike interviews or focus groups that attempt to get users to accurately self-report their own behaviour or preferences, a well-designed user test measures actual performance on mission-critical tasks.</p>
              <p>At the core of any user study is a small set of three to five design hypotheses. The goal of your study is to validate or invalidate those hypotheses. The next iteration of the design will change accordingly.</p>
              <p>The goal is to get qualitative feedback on a single design iteration from multiple participants. By keeping the sessions identical (or as similar to one another as possible), you’ll be able to suss out the commonalities between them.</p>

              <p class="h3 subheading padding-0 margin-0">Why do we need it?</p>
              <p>There are many advantages of usability testing including:</p>
              <ul>
                <li>feedback direct from the target audience</li>
                <li>internal debates can be resolved by testing the issue to see how users react to the different options being discussed</li>
                <li>issues and potential problems are highlighted before the product is developed and launched</li>
                <li>it minimises the risk of new designs failing</li>
                <li>users are better able to reach their goals, which results in the business meeting its targets</li>
              </ul>

              <p class="h3 subheading padding-0 margin-0">Who are we testing?</p>
              <p>Users should be outsiders who are not involved in the changes we are testing in any way. This can be members of our extended team if they have been in no way involved in the design changes so far, but should also reach beyond the team. This can include staff from other teams across iiNet, such as CSRs and CSMs, and even customers in the Store downstairs (although this may require an incentive). </p>
              <p>The best results come from testing no more than 5 users and running as many small tests as practical, as 5 users are enough to uncover the majority of potential usability issues. Rather than fixating on the number of test participants, you’ll find more usability problems in your test by including a variety of tasks, than you will by including more participants. </p>

              <p class="h3 subheading padding-0 margin-0">When to conduct a user test</p>
              <p>Virtually anything can be user tested, but it is best to reserve it for larger projects. For example a redesign of an existing page, changes to our UI or IA, changes to page layouts, and new product launches.</p>
              <p>Testing little and often is far more valuable and cost effective than doing one whopping big usability test of an entire site when it is almost finished.</p>
              <p>Suitable times for testing:</p>
              <ul>
                <li>at a web page’s conception (start by testing a mockup of the page)</li>
                <li>before planning a development</li>
                <li>repeatedly during (re)development, as critical pages or sections are prepared</li>
                <li>when traffic analysis shows an anomaly</li>
                <li>when the product owner requires hard information about a page or site</li>
              </ul>
              <p>Tests may range from 5 minutes (for a single page design) to 1 hour (for a general response or new design).</p>

              <p class="h3 subheading padding-0 margin-0">Types of user tests</p>
              <p><strong>Comparative Testing</strong></p>
              <p>Used to compare the usability of one website with another. Comparative tests are commonly used to compare a website against peer or competitor sites, however it can also be used to compare two designs to establish which provides the best user experience. </p>
              <p><strong>Explorative Testing</strong></p>
              <p>Before a new product is released, explorative usability testing can establish what content and functionality a new product should include to meet the needs of its users. Users test a range of different services where they are given realistic scenarios to complete which helps to highlight any gaps in the market that can be taken advantage of and illustrate where to focus design effort. </p>
              <p><strong>Usability Evaluation</strong></p>
              <p>This is a test of a new or updated service either pre or post-launch. This usability test introduces users to the new design to ensure it is intuitive to use and provides a positive user experience. The aim of the usability evaluation is to ensure any potential issues are highlighted and fixed before the product is launched.</p>
              <p><strong>Preference Testing</strong></p>
              <p>Preference testing can assist teams in determining which approach to run with in a lean and cost effective fashion, independent of internal personality conflicts or petty political battles.</p>
              <p>While the statistically meaningful solution is to launch both versions and validate success via A/B Testing, often times companies do not have the bandwidth or time to create and support multiple versions of a site. Akin to competitive testing your product against itself, Preference Testing with remote users can help you get a few user opinions to back up which product to launch.</p>

              <p>Depending what stage you are at in the design process, work out which type of testing is the most appropriate. You may write a test that approaches multiple topics</p>

              <p class="h3 subheading padding-0 margin-0">How to conduct a user test</p>
              <p><strong>A good user test has clear and measurable outcomes</strong></p>
              <p>If you have clear expectations, it will be much easier to take action on what you learn. When you’re asking open-ended tasks and questions, you still need to make sure you have a clear objective in mind. (For example, “Can visitors find the product they’re looking for?”) If you don’t know what you want to learn, your test participants may wander around aimlessly without uncovering anything useful. Make sure that your tasks and questions support the ultimate goal of your research.</p>
              <p>This is often accomplished with hypotheses: testable statements you assume to be true for the purposes of validation. Examples of good hypotheses include:</p>
              <ul>
                <li>Users can add an item to their shopping cart and check out within five minutes</li>
                <li>Users can bundle broadband and mobile to receive a discount without confusion</li>
                <li>Users know how to determine which broadband product is right for them</li>
              </ul>
              <p>It starts with a small set of design questions. You take those questions, reformulate them as hypotheses, devise a plan for validating the hypotheses, and conduct five or six user tests. Once done, you summarise the results and decide on next steps. If the findings were clear, you might make improvements to the design. If the findings were unclear, you might conduct additional test sessions.</p>
              <p><strong>A good user test must be sufficiently detailed and interactive</strong></p>
              <p>If you want to measure a user’s reaction to an on-screen animation, you will need a coded prototype. If you need to decide whether a particular screen can be omitted from the final design, a set of PSD mockups will do. Know what you hope to discover each time you test.</p>
              <p>With all tests you want to discover whether the user:</p>
              <ul>
                <li>gets the point of the page(s)</li>
                <li>understands the navigation system</li>
                <li>can guess where to find things.</li>
              </ul>
              <p>In a general test you want to know:</p>
              <ul>
                <li>how do users interact with the web site you are testing?</li>
                <li>what is difficult for people to do?</li>
                <li>where do they get lost?</li>
                <li>what makes sense to them?</li>
                <li>what makes them feel insecure?</li>
                <li>what do they like and what do they hate?</li>
              </ul>
              <p>In a specific test you might want to know, for example:</p>
              <ul>
                <li>can the user accomplish a key task?</li>
                <li>can the user find something specific?</li>
              </ul>

              <p class="h3 subheading padding-0 margin-0">Writing a test plan</p>
              <p><strong>1. Define the test objective</strong></p>
              <p>Just like any scientific experiment, the first step of setting up a user test is identifying the question you’re hoping to answer. Share it with any stakeholders to make sure everyone understands why you’re running the test and what you can expect to learn. </p>
              <p><strong>2. Choose demographics</strong></p>
              <p>Who do you want feedback from? Will this page be used by customers / CSRs / internal staff?</p>
              <p><strong>3. Choosing the device and other requirements:</strong></p>
              <p>What do your test participants need to have in order to give you the feedback you need?</p>
              <p><strong>4. Selecting tasks and questions:</strong></p>
              <p>What do you want to watch users do? Open ended vs closed questions…</p>
              <p>While the statistically meaningful solution is to launch both versions and validate success via A/B Testing, often times companies do not have the bandwidth or time to create and support multiple versions of a site. Akin to competitive testing your product against itself, Preference Testing with remote users can help you get a few user opinions to back up which product to launch.</p>
              <p><strong>5. Analysing the results:</strong></p>
              <p>From the notes you take during the testing session, decide what actions need to be taken. Some problems identified will be of higher importance than others. If major changes are required, further testing may be appropriate.</p>

              <p class="h3 subheading padding-0 margin-0">Things to remember:</p>
              <ul>
                <li>Users don’t know what they need. Asking them what they want is rarely a winning strategy. Instead, you’re better off being a silent observer. Give them an interactive design and watch them perform real tasks with it.</li>
                <li>Don’t accept what a single person says at face value. Until you get signal from several people that a design is flawed, withhold judgment. Once five or six participants have given consistent feedback, change the design.</li>
                <li>Waiting for things to be perfect sets everything up for a one off usability test which tries to answer everything and ultimately comes as unwanted negative feedback. Instead, try to think of usability testing in terms of helping you to prioritise your to-do list. Stop thinking of a usability test as a one off event, and instead as an ongoing tool to help you isolate and fix issues earlier in the lifecycle. You’ll soon find that it takes less time and energy to fix issues earlier on than it is nearer project launch</li>
              </ul>

            </div>
            <!-- end page specific content -->


          <!-- end container -->


        </article>

      </div>

    </div>
  </div>
  <!-- end iiNet Plan Refreshes -->

  <!-- include footer -->
  <?php include('inc/_footer.php'); ?>

  <!-- page specific scripts -->
  <script>
    // OWL CAROUSEL - initiate Owl Carousel plugin
    $('.owl-carousel').owlCarousel({
      stagePadding: 0,
      //lazyLoad: true,
      loop: false,
      margin: 10,
      nav: false,
      responsive: {
        0: {
          items: 1
        },
        600: {
          items: 1
        },
        1400: {
          items: 1
        }
      }
    });
  </script>


</body>